理解LangGraph需要先掌握马尔可夫决策过程（MDP），因为LangGraph的核心设计灵感来源于MDP的状态转移和决策机制，将AI代理的工作流建模为一个动态的、有状态的决策过程。[3]

## MDP基础概念
马尔可夫决策过程是一个五元组\( \langle S, A, P, R, \gamma \rangle \)，其中\( S \)是状态空间，\( A \)是动作空间，\( P \)是状态转移概率，\( R \)是奖励函数，\( \gamma \)是折扣因子。下一个状态仅依赖当前状态和动作，具有马尔可夫性质，即历史信息不影响未来转移。[6][3]

## LangGraph的设计关联
LangGraph使用图结构表示代理的状态机，每个节点代表一个状态（如思考、调用工具），边代表动作导致的状态转移，这直接映射MDP的决策循环。代理通过策略（如LLM决策）从当前状态选择动作，推动流程前进，避免无序执行。[7]

## 学习路径益处
先理解MDP能帮助把握LangGraph中状态持久化、循环控制和最优策略求解（如价值迭代），从而构建可靠的多代理系统，而非简单线性链。[9][3]

[1](https://blog.csdn.net/m0_59614665/article/details/151114626)
[2](https://www.53ai.com/news/langchain/2025102358927.html)
[3](https://cloud.tencent.com/developer/article/2297123)
[4](https://qiankunli.github.io/2023/10/30/from_attention_to_transformer.html)
[5](https://cloud.tencent.com/developer/article/1916373)
[6](https://leovan.me/cn/2020/05/markov-decision-process/)
[7](https://juejin.cn/post/7574253222607011881)
[8](https://www.jiqizhixin.com/graph/technologies/c8ec6a47-6bf7-4575-abae-cf2a1db61989)
[9](https://blog.csdn.net/EasyMCM/article/details/150445264)
[10](https://chenrudan.github.io/blog/2016/06/12/reinforcementlearninglesssion2.html)
[11](https://developer.aliyun.com/article/1254762)
[12](https://www.cnblogs.com/jsfantasy/p/jsfantasy.html)
[13](https://blog.csdn.net/november_chopin/article/details/106589197)
[14](https://zh.wikipedia.org/zh-hans/%E9%A6%AC%E5%8F%AF%E5%A4%AB%E6%B1%BA%E7%AD%96%E9%81%8E%E7%A8%8B)
[15](https://hrl.boyuai.com/chapter/1/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/)
[16](https://rl.qiwihui.com/zh-cn/latest/partI/chapter3/finite_markov_decision_process.html)