# LangGraph 状态持久化（Checkpointing）和时间旅行详解

## 目录

1. [概述](#概述)
2. [核心概念](#核心概念)
3. [Checkpoint 机制](#checkpoint-机制)
4. [时间旅行（Time Travel）](#时间旅行time-travel)
5. [实际应用场景](#实际应用场景)
6. [代码示例](#代码示例)
7. [实现细节](#实现细节)

---

## 概述

LangGraph 的状态持久化（Checkpointing）是一个强大的功能，它允许在图的执行过程中保存和恢复状态。这个机制使得以下功能成为可能：

- **记忆（Memory）**：在多次交互之间保持状态
- **时间旅行（Time Travel）**：回放和调试历史执行
- **人机交互（Human-in-the-loop）**：允许人类检查和修改执行状态
- **容错（Fault-tolerance）**：从错误中恢复执行

### 为什么需要 Checkpointing？

在复杂的 AI 代理系统中，状态管理至关重要：

1. **长期运行的任务**：某些任务可能需要很长时间才能完成，需要能够暂停和恢复
2. **非确定性系统**：基于 LLM 的决策可能产生不同的结果，需要能够回溯和探索不同路径
3. **调试和优化**：需要能够查看历史状态，理解代理的决策过程
4. **多租户支持**：不同用户或会话需要独立的状态空间

---

## 核心概念

### Thread（线程）

**Thread** 是一个唯一标识符，用于标识一系列相关的 checkpoint。它类似于对话会话的概念：

- 每个 thread 包含多个 checkpoint
- 同一个 thread 内的 checkpoint 形成一条执行历史链
- 不同的 thread 之间状态完全隔离

```python
# 创建或使用一个 thread
config = {"configurable": {"thread_id": "user_123_session_1"}}
```

**使用场景**：
- 多用户聊天应用：每个用户会话是一个独立的 thread
- 多任务处理：每个任务是一个独立的 thread
- 实验和调试：不同的实验使用不同的 thread

### Checkpoint（检查点）

**Checkpoint** 是图状态在某个特定时间点的快照。它包含：

1. **状态值（values）**：所有通道（channel）的当前值
2. **通道版本（channel_versions）**：每个通道的版本号
3. **已见版本（versions_seen）**：每个节点看到的通道版本
4. **元数据（metadata）**：包括步骤号、来源等信息
5. **下一个节点（next）**：接下来要执行的节点列表
6. **任务（tasks）**：待执行的任务信息

#### Checkpoint 的结构

```python
StateSnapshot(
    values={'foo': 'b', 'bar': ['a', 'b']},  # 状态值
    next=('node_b',),                         # 下一个要执行的节点
    config={'configurable': {
        'thread_id': '1',
        'checkpoint_id': '1ef663ba-28fe-6528-8002-5a559208592c'
    }},
    metadata={
        'source': 'loop',                     # 来源：input/loop/update/fork
        'step': 2,                           # 步骤号
        'writes': {'node_b': {'foo': 'b', 'bar': ['b']}}
    },
    created_at='2024-08-29T19:19:38.821749+00:00',
    parent_config={...},                     # 父 checkpoint 的配置
    tasks=(...)                              # 待执行的任务
)
```

### Superstep（超级步骤）

**Superstep** 是图执行的一个迭代周期：

- 在一个 superstep 中，多个节点可以并行执行
- 每个 superstep 结束时，会创建一个 checkpoint
- checkpoint 记录了该 superstep 完成后的完整状态

**执行流程**：
```
Superstep 0: START → 创建 checkpoint 0
Superstep 1: node_a 执行 → 创建 checkpoint 1
Superstep 2: node_b 执行 → 创建 checkpoint 2
Superstep 3: END → 创建 checkpoint 3（最终状态）
```

---

## Checkpoint 机制

### 自动保存

当图使用 checkpointer 编译时，会在每个 superstep 结束时自动保存 checkpoint：

```python
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, START, END

# 创建 checkpointer
checkpointer = InMemorySaver()

# 编译图时指定 checkpointer
graph = workflow.compile(checkpointer=checkpointer)

# 执行图（必须指定 thread_id）
config = {"configurable": {"thread_id": "1"}}
result = graph.invoke({"foo": ""}, config)
```

### Checkpoint 保存时机

Checkpoint 在以下时机被保存：

1. **输入时（source: "input"）**：图开始执行时，保存初始输入状态
2. **循环中（source: "loop"）**：每个 superstep 完成后
3. **手动更新（source: "update"）**：通过 `update_state()` 手动更新状态时
4. **分支（source: "fork"）**：从某个 checkpoint 创建新分支时

### 查看 Checkpoint

#### 获取最新状态

```python
# 获取 thread 的最新状态
config = {"configurable": {"thread_id": "1"}}
latest_state = graph.get_state(config)
print(latest_state.values)
print(latest_state.next)
```

#### 获取历史状态

```python
# 获取指定 checkpoint 的状态
config = {
    "configurable": {
        "thread_id": "1",
        "checkpoint_id": "1ef663ba-28fe-6528-8002-5a559208592c"
    }
}
specific_state = graph.get_state(config)
```

#### 获取完整历史

```python
# 获取所有 checkpoint（按时间倒序）
config = {"configurable": {"thread_id": "1"}}
history = list(graph.get_state_history(config))

for state in history:
    print(f"Step {state.metadata['step']}: {state.values}")
    print(f"Next nodes: {state.next}")
    print(f"Checkpoint ID: {state.config['configurable']['checkpoint_id']}")
    print("---")
```

**输出示例**：
```
Step 2: {'foo': 'b', 'bar': ['a', 'b']}
Next nodes: ()
Checkpoint ID: 1ef663ba-28fe-6528-8002-5a559208592c
---
Step 1: {'foo': 'a', 'bar': ['a']}
Next nodes: ('node_b',)
Checkpoint ID: 1ef663ba-28f9-6ec4-8001-31981c2c39f8
---
Step 0: {'foo': '', 'bar': []}
Next nodes: ('node_a',)
Checkpoint ID: 1ef663ba-28f4-6b4a-8000-ca575a13d36a
---
```

---

## 时间旅行（Time Travel）

时间旅行是 checkpointing 最强大的功能之一，允许你：

1. **回放历史执行**：从任意 checkpoint 重新执行
2. **探索替代路径**：修改状态后重新执行
3. **调试问题**：查看历史状态，理解执行流程

### 回放（Replay）

从指定的 checkpoint 重新执行图：

```python
# 从特定 checkpoint 重新执行
config = {
    "configurable": {
        "thread_id": "1",
        "checkpoint_id": "1ef663ba-28f9-6ec4-8001-31981c2c39f8"
    }
}

# 使用 None 作为输入，表示从 checkpoint 恢复
result = graph.invoke(None, config)
```

**重要特性**：
- LangGraph 知道哪些步骤已经执行过
- 对于 checkpoint_id **之前**的步骤，会直接回放（不重新执行）
- 对于 checkpoint_id **之后**的步骤，会重新执行（创建新分支）

### 状态修改和分支（Fork）

修改历史状态并创建新分支：

```python
# 1. 获取历史 checkpoint
history = list(graph.get_state_history(config))
selected_checkpoint = history[1]  # 选择第二个 checkpoint

# 2. 查看当前状态
print(selected_checkpoint.values)  # {'topic': 'socks'}

# 3. 修改状态（创建新分支）
new_config = graph.update_state(
    selected_checkpoint.config,
    values={"topic": "chickens"}  # 修改主题
)

# 4. 从新分支继续执行
result = graph.invoke(None, new_config)
```

**分支特性**：
- `update_state()` 会创建一个新的 checkpoint
- 新 checkpoint 属于同一个 thread，但有新的 checkpoint_id
- 从新 checkpoint 执行会创建新的执行路径（fork）

### 完整的时间旅行示例

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from typing_extensions import TypedDict

class State(TypedDict):
    topic: str
    joke: str

def generate_topic(state: State):
    return {"topic": "socks"}

def write_joke(state: State):
    return {"joke": f"Why did the {state['topic']} cross the road?"}

# 构建图
workflow = StateGraph(State)
workflow.add_node("generate_topic", generate_topic)
workflow.add_node("write_joke", write_joke)
workflow.add_edge(START, "generate_topic")
workflow.add_edge("generate_topic", "write_joke")
workflow.add_edge("write_joke", END)

# 编译
checkpointer = InMemorySaver()
graph = workflow.compile(checkpointer=checkpointer)

# 1. 首次执行
config = {"configurable": {"thread_id": "1"}}
result1 = graph.invoke({}, config)
print("首次执行结果:", result1)

# 2. 查看历史
history = list(graph.get_state_history(config))
print(f"\n共有 {len(history)} 个 checkpoint")

# 3. 选择中间的 checkpoint（在 generate_topic 之后）
selected = history[1]  # 第二个 checkpoint
print(f"\n选择的 checkpoint:")
print(f"  状态: {selected.values}")
print(f"  下一步: {selected.next}")

# 4. 修改状态并创建分支
new_config = graph.update_state(
    selected.config,
    values={"topic": "chickens"}  # 修改主题
)

# 5. 从新分支继续执行
result2 = graph.invoke(None, new_config)
print(f"\n分支执行结果: {result2}")

# 6. 查看新的历史（包含分支）
new_history = list(graph.get_state_history(new_config))
print(f"\n新分支共有 {len(new_history)} 个 checkpoint")
```

---

## 实际应用场景

### 1. 对话记忆（Conversation Memory）

在聊天应用中，checkpointing 使得代理能够记住之前的对话：

```python
# 第一次对话
config = {"configurable": {"thread_id": "user_123"}}
response1 = graph.invoke(
    {"messages": [{"role": "user", "content": "我叫张三"}]},
    config
)

# 第二次对话（使用相同的 thread_id）
# 图会自动加载之前的状态
response2 = graph.invoke(
    {"messages": [{"role": "user", "content": "我的名字是什么？"}]},
    config
)
# 代理会记得用户的名字是"张三"
```

### 2. 调试和错误恢复

当执行出错时，可以从最后一个成功的 checkpoint 恢复：

```python
try:
    result = graph.invoke(input_data, config)
except Exception as e:
    # 获取最后一个成功的 checkpoint
    history = list(graph.get_state_history(config))
    if history:
        last_successful = history[0]  # 最新的 checkpoint
        print(f"从 checkpoint {last_successful.config['configurable']['checkpoint_id']} 恢复")
        # 修复问题后继续执行
        result = graph.invoke(None, last_successful.config)
```

### 3. A/B 测试和实验

通过分支功能，可以测试不同的策略：

```python
# 原始执行
config = {"configurable": {"thread_id": "experiment_1"}}
result_a = graph.invoke(input_data, config)

# 从某个 checkpoint 创建分支，测试不同策略
history = list(graph.get_state_history(config))
fork_point = history[2]  # 选择分支点

# 策略 A
config_a = graph.update_state(fork_point.config, values={"strategy": "A"})
result_a = graph.invoke(None, config_a)

# 策略 B
config_b = graph.update_state(fork_point.config, values={"strategy": "B"})
result_b = graph.invoke(None, config_b)

# 比较结果
compare_results(result_a, result_b)
```

### 4. 人机交互（Human-in-the-loop）

允许人类在关键决策点介入：

```python
# 设置中断点
graph = workflow.compile(
    checkpointer=checkpointer,
    interrupt_before=["approval_node"]  # 在 approval_node 之前中断
)

# 执行到中断点
config = {"configurable": {"thread_id": "1"}}
for event in graph.stream(input_data, config):
    print(event)

# 人类检查状态并修改
current_state = graph.get_state(config)
if needs_modification(current_state):
    # 人类修改状态
    new_config = graph.update_state(
        config,
        values={"human_feedback": "修改后的内容"}
    )
    # 继续执行
    graph.invoke(None, new_config)
```

---

## 代码示例

### 示例 1：基本 Checkpointing

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from typing_extensions import TypedDict

class State(TypedDict):
    counter: int
    history: list[str]

def increment(state: State):
    new_value = state.get("counter", 0) + 1
    return {
        "counter": new_value,
        "history": state.get("history", []) + [f"Step {new_value}"]
    }

# 构建图
workflow = StateGraph(State)
workflow.add_node("increment", increment)
workflow.add_edge(START, "increment")
workflow.add_edge("increment", END)

# 编译并执行
checkpointer = InMemorySaver()
graph = workflow.compile(checkpointer=checkpointer)

config = {"configurable": {"thread_id": "counter_demo"}}

# 第一次执行
result1 = graph.invoke({"counter": 0, "history": []}, config)
print("第一次:", result1)

# 第二次执行（状态会累积）
result2 = graph.invoke({}, config)  # 空输入，使用之前的状态
print("第二次:", result2)

# 查看历史
history = list(graph.get_state_history(config))
for i, state in enumerate(history):
    print(f"Checkpoint {i}: counter={state.values.get('counter')}, "
          f"history={state.values.get('history')}")
```

### 示例 2：时间旅行和分支

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from typing_extensions import TypedDict

class State(TypedDict):
    decision: str
    result: str

def make_decision(state: State):
    # 模拟基于某些条件的决策
    if state.get("decision") == "A":
        return {"result": "选择了路径 A"}
    else:
        return {"result": "选择了路径 B"}

workflow = StateGraph(State)
workflow.add_node("make_decision", make_decision)
workflow.add_edge(START, "make_decision")
workflow.add_edge("make_decision", END)

checkpointer = InMemorySaver()
graph = workflow.compile(checkpointer=checkpointer)

config = {"configurable": {"thread_id": "decision_demo"}}

# 原始执行：选择 A
result_a = graph.invoke({"decision": "A"}, config)
print("原始路径 A:", result_a)

# 获取历史，找到决策点
history = list(graph.get_state_history(config))
decision_point = history[1]  # 决策前的 checkpoint

# 创建分支：选择 B
config_b = graph.update_state(
    decision_point.config,
    values={"decision": "B"}
)
result_b = graph.invoke(None, config_b)
print("分支路径 B:", result_b)

# 现在有两个不同的执行路径
print("\n路径 A 历史:")
for state in graph.get_state_history(config):
    print(f"  {state.values}")

print("\n路径 B 历史:")
for state in graph.get_state_history(config_b):
    print(f"  {state.values}")
```

### 示例 3：错误恢复

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from typing_extensions import TypedDict

class State(TypedDict):
    step: int
    data: list[str]

def process_step(state: State):
    step = state.get("step", 0)
    if step == 2:
        raise ValueError("模拟错误发生在步骤 2")
    return {
        "step": step + 1,
        "data": state.get("data", []) + [f"Processed step {step + 1}"]
    }

workflow = StateGraph(State)
workflow.add_node("process_step", process_step)
workflow.add_edge(START, "process_step")
workflow.add_edge("process_step", END)

checkpointer = InMemorySaver()
graph = workflow.compile(checkpointer=checkpointer)

config = {"configurable": {"thread_id": "error_recovery_demo"}}

# 执行到错误
try:
    result = graph.invoke({"step": 0, "data": []}, config)
except ValueError as e:
    print(f"捕获错误: {e}")
    
    # 获取最后一个成功的 checkpoint
    history = list(graph.get_state_history(config))
    if history:
        last_successful = history[0]
        print(f"\n最后一个成功的状态:")
        print(f"  步骤: {last_successful.values.get('step')}")
        print(f"  数据: {last_successful.values.get('data')}")
        
        # 修复问题后继续
        print("\n修复问题后继续执行...")
        # 修改状态，跳过有问题的步骤
        fixed_config = graph.update_state(
            last_successful.config,
            values={"step": 3}  # 跳过步骤 2
        )
        result = graph.invoke(None, fixed_config)
        print(f"恢复后结果: {result}")
```

---

## 实现细节

### Checkpoint 数据结构

```python
class Checkpoint(TypedDict):
    v: int                          # Checkpoint 格式版本
    id: str                         # 唯一且单调递增的 ID
    ts: str                         # ISO 8601 时间戳
    channel_values: dict[str, Any]   # 通道值快照
    channel_versions: dict[str, int] # 通道版本号
    versions_seen: dict[str, dict]   # 每个节点看到的通道版本
    updated_channels: list[str] | None # 本次更新的通道列表
```

### CheckpointSaver 接口

所有 checkpoint saver 必须实现以下方法：

```python
class BaseCheckpointSaver:
    def put(self, config, checkpoint, metadata, pending_writes):
        """保存 checkpoint"""
        pass
    
    def get_tuple(self, config):
        """获取 checkpoint tuple"""
        pass
    
    def list(self, config, filter=None, before=None, limit=None):
        """列出匹配的 checkpoint"""
        pass
    
    def put_writes(self, config, writes, task_id):
        """保存待处理的写入（pending writes）"""
        pass
```

### 可用的 CheckpointSaver 实现

1. **InMemorySaver**：内存实现，用于开发和测试
   ```python
   from langgraph.checkpoint.memory import InMemorySaver
   checkpointer = InMemorySaver()
   ```

2. **SqliteSaver**：SQLite 数据库实现，适合本地开发
   ```python
   from langgraph.checkpoint.sqlite import SqliteSaver
   import sqlite3
   checkpointer = SqliteSaver(sqlite3.connect("checkpoints.db"))
   ```

3. **PostgresSaver**：PostgreSQL 实现，适合生产环境
   ```python
   from langgraph.checkpoint.postgres import PostgresSaver
   checkpointer = PostgresSaver.from_conn_string("postgresql://...")
   ```

### Pending Writes（待处理写入）

当某个 superstep 中部分节点失败时，LangGraph 会保存已成功节点的写入：

```python
# Superstep 中有 3 个节点：A, B, C
# A 和 B 成功，C 失败
# LangGraph 会保存 A 和 B 的写入作为 pending writes
# 当从该 checkpoint 恢复时，A 和 B 不会重新执行
```

### 序列化（Serialization）

Checkpoint 需要序列化状态值以便存储：

- **默认序列化器**：`JsonPlusSerializer`，支持多种类型
- **自定义序列化**：可以实现 `SerializerProtocol` 接口
- **加密序列化**：可以使用 `EncryptedSerializer` 加密敏感数据

```python
from langgraph.checkpoint.serde.jsonplus import JsonPlusSerializer
from langgraph.checkpoint.serde.encrypted import EncryptedSerializer

# 使用加密序列化器
serde = EncryptedSerializer.from_pycryptodome_aes()  # 从环境变量读取密钥
checkpointer = InMemorySaver(serde=serde)
```

---

## 总结

LangGraph 的 Checkpointing 机制提供了强大的状态管理能力：

1. **自动持久化**：每个 superstep 自动保存状态
2. **时间旅行**：可以回放和修改历史状态
3. **分支探索**：从任意点创建新分支，探索不同路径
4. **容错恢复**：从错误中恢复，不丢失已完成的工作
5. **多租户支持**：通过 thread 隔离不同会话

这些功能使得 LangGraph 非常适合构建：
- 长期运行的 AI 代理
- 需要记忆的对话系统
- 需要调试和优化的复杂工作流
- 需要人类介入的决策系统

通过合理使用 checkpointing，你可以构建更加健壮、可调试、可恢复的 AI 应用。
